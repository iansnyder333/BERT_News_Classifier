{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Investigation to Reproduce the findings in:\n",
    "\n",
    "## “Low-Resource” Text Classification: A Parameter-Free Classification Method with Compressors\n",
    "\n",
    "#### Zhiying Jiang1,2, Matthew Y.R. Yang1, Mikhail Tsirlin1, Raphael Tang1, Yiqin Dai2 and Jimmy Lin1\n",
    "\n",
    "#### Reproduction by Ian Snyder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intuition of using compressors for classification is that:\n",
    "- compressors are good at capturing regularity\n",
    "- objects from the same category share more regularity than those from different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(\"/Users/iansnyder/Desktop/Projects/NER_proj/data/bbc-text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.8 * len(data))\n",
    "v = int(0.1 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:n+v]\n",
    "labels = {\"business\": 0, \"entertainment\": 1, \"sport\": 2, \"tech\": 3, \"politics\": 4}\n",
    "train_data = train_data.replace({\"category\": labels})\n",
    "val_data = val_data.replace({\"category\": labels})\n",
    "train_data = np.array([(row[\"text\"], row[\"category\"]) for _, row in train_data.iterrows()])\n",
    "val_data = np.array([(row[\"text\"], row[\"category\"]) for _, row in val_data.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [02:40<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "results = []\n",
    "#for each (text,label) in validation set\n",
    "for (x1, _) in tqdm(val_data):\n",
    "    #calculate the compressed length of the utf-8 encoded text\n",
    "    Cx1 = len(gzip.compress(x1.encode()))\n",
    "    #create a distance array\n",
    "    distance_from_x1 = []\n",
    "    #for each (text,label) in training set\n",
    "    for (x2,_) in train_data:\n",
    "        #calculate the compressed length of the utf-8 encoded text\n",
    "        Cx2 = len(gzip.compress(x2.encode()))\n",
    "        #concatenate the two texts\n",
    "        x1x2 = \" \".join([x1, x2])\n",
    "        #calculate the compressed length of the utf-8 encoded concatenated text\n",
    "        Cx1x2 = len(gzip.compress(x1x2.encode()))\n",
    "        #calculate the normalized compression distance: a normalized version of information distance\n",
    "        ncd = (Cx1x2 - min(Cx1,Cx2)) / max(Cx1, Cx2)\n",
    "        #append the distance to the distance array\n",
    "        distance_from_x1.append(ncd)\n",
    "    #sort the distance array and get the top k classes\n",
    "    sorted_idx = np.argsort(np.array(distance_from_x1))\n",
    "    #get the top k classes\n",
    "    top_k_class = train_data[sorted_idx[:k], 1]\n",
    "    #get the most frequent class based on the top k classes\n",
    "    predict_class = max(set(top_k_class), key = list(top_k_class).count)\n",
    "    #append the predicted class to the results array\n",
    "    results.append(predict_class)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This intuition can be formalized as a distance met- ric derived from Kolmogorov complexity (Kol- mogorov, 1963). Kolmogorov complexity K (x) characterizes the length of the shortest binary pro- gram that can generate x. K(x) is theoretically the ultimate lower bound for information measurement.\n",
    "\n",
    "The intuition behind using compressed length is that the length of x that has been maximally com- pressed by a compressor is close to K(x). Gener- ally, the higher the compression ratio, the closer C(x) is to K(x).\n",
    "\n",
    " C(x) here means the length of x af- ter being compressed by gzip. C(xy) is the com- pressed length of concatenation of x and y. With the distance matrix NCD provides, we can then use k-nearest-neighbor to perform classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is: 0.963963963963964\n",
      "The Standard Deviation is: 0.18637982761781263\n",
      "The F1 Score is: 0.9603174603174602\n"
     ]
    }
   ],
   "source": [
    "#calculate the accuracy\n",
    "accuracy = np.sum(results == val_data[:,1]) / len(val_data)\n",
    "#calculate standard deviation\n",
    "std = np.std(results == val_data[:,1])\n",
    "print(f\"The Accuracy is: {accuracy}\\nThe Standard Deviation is: {std}\")\n",
    "\n",
    "# calculate the f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(val_data[:,1], results, average='macro')\n",
    "print(f\"The F1 Score is: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model has extremely impressive accuracy, outperforming the BERT model and only taking 2 minutes to run on a 2016 macbook pro with 2 GHz Dual-Core Intel Core i5. \n",
    "\n",
    "Compared to my BERT Fine-Tuning on the same dataset and same hardware, this method had equal accuracy, but ran 15 times faster and used 72,000 times less storage. Not to mention several hours saved with the minimal preprocessing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
